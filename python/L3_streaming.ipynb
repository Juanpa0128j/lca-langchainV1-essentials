{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483ab18e-f419-46ad-9bbe-171ffd05f983",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "<img src=\"./assets/LC_streaming.png\" width=\"400\">\n",
    "\n",
    "Streaming reduces the latency between generating data and the user receiving it.\n",
    "There are two types frequently used with Agents:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f0f22c-9724-46ce-baf3-60a2de701fb3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b76bab7-fa52-46f4-86bc-b157067e0168",
   "metadata": {},
   "source": [
    "Load and/or check for needed environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2fcfd93-0004-4ff1-9b60-0b21baf68c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY=****tM0A\n",
      "LANGSMITH_API_KEY=****bc46\n",
      "LANGSMITH_TRACING=true\n",
      "LANGSMITH_PROJECT=****ials\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from env_utils import doublecheck_env\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Check and print results\n",
    "doublecheck_env(\"example.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "166fc0b1-2322-4dd2-a358-89309fb9f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a26b4586-453a-4c10-9fae-4be3f4cb6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5\",\n",
    "    system_prompt=\"You are a full-stack comedian\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a907aa9-a608-47e2-92d4-6758a1728cb2",
   "metadata": {},
   "source": [
    "## No Steaming (invoke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc384cf0-b208-4ab1-b7e2-f4b93dab08bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do programmers prefer dark mode? Because light attracts bugs.\n",
      "\n",
      "Want another—tech, dad, or wordplay?\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke\"}]})\n",
    "print(result[\"messages\"][1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d7975-8d94-4d5e-8493-e68ac9fcedf9",
   "metadata": {},
   "source": [
    "## values\n",
    "You have seen this streaming mode in our examples so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e30a2273-1dd3-47e8-a38e-05ed4b750000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Tell me a Dad joke\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I’m reading a book on anti-gravity—it's impossible to put down.\n"
     ]
    }
   ],
   "source": [
    "# Stream = values\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a Dad joke\"}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada88835-3c66-4241-b3d9-4f3d38390c86",
   "metadata": {},
   "source": [
    "## messages\n",
    "Messages stream data token by token - the lowest latency possible. This is perfect for interactive applications like chatbots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a9cc553-7357-4d36-b88d-25eaf7462cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In our bright and bouncy house, the day begins with cheer,\n",
      "Toast pops up like parachutes and jelly lands near.\n",
      "\n",
      "The milk does tiny cartwheels, the cereal shouts “Hooray!”\n",
      "A sock plays hide-and-seek and wins by running away.\n",
      "\n",
      "The dog’s our doorbell manager, with wags for every guest,\n",
      "The cat audits all laps and chooses only the best.\n",
      "\n",
      "Our chore chart’s a treasure map with Gold Star Island’s glow,\n",
      "We battle Mount Laundry and the Dust-Bunny snow.\n",
      "\n",
      "At homework time, the Wi‑Fi is a dragon we befriend—\n",
      "We offer snacks of patience till the loading bars will bend.\n",
      "\n",
      "We measure out our laughter like sprinkles on a cake,\n",
      "And pass around the giggles when a pun needs a break.\n",
      "\n",
      "At dinner, tiny trees of broccoli grow tall,\n",
      "We are giants in the forest taking teeny bites of all.\n",
      "\n",
      "The dishes start a drumline in the sink’s tin band,\n",
      "We clap with soapy mittens like a squeaky washing hand.\n",
      "\n",
      "Then toothbrushes perform a minty lullaby,\n",
      "And pajamas parade under moonlight’s tie-dye.\n",
      "\n",
      "Night-lights turn to lighthouses guiding dreams anew—\n",
      "We may not match our socks, but our hearts always do."
     ]
    }
   ],
   "source": [
    "for token, metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Write me a family friendly poem.\"}]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    print(f\"{token.content}\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c4477-24ff-4321-8f50-aff3324fa831",
   "metadata": {},
   "source": [
    "## Tools can stream too!\n",
    "Streaming generally means delivering information to the user before the final result is ready. There are many cases where this is useful. A `get_stream_writer` writer allows you to easily stream `custom` data from sources you create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c68179e6-d388-494a-b10d-109c230f6ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='2925fabf-3c7e-4a14-9a72-531240436fbf')]})\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='2925fabf-3c7e-4a14-9a72-531240436fbf'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 132, 'total_tokens': 222, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Ca9Mw5d8Cqw2CIFh7xs3xeT7LnCbe', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--390b0a79-531d-4131-8cba-c548963eab78-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco, CA'}, 'id': 'call_Qyj7WfAgzWGCmbyM6EcPEnsf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 90, 'total_tokens': 222, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}})]})\n",
      "('custom', 'Looking up data for city: San Francisco, CA')\n",
      "('custom', 'Acquired data for city: San Francisco, CA')\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='2925fabf-3c7e-4a14-9a72-531240436fbf'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 132, 'total_tokens': 222, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Ca9Mw5d8Cqw2CIFh7xs3xeT7LnCbe', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--390b0a79-531d-4131-8cba-c548963eab78-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco, CA'}, 'id': 'call_Qyj7WfAgzWGCmbyM6EcPEnsf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 90, 'total_tokens': 222, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}), ToolMessage(content=\"It's always sunny in San Francisco, CA!\", name='get_weather', id='da404a4e-7ca0-4c28-b19d-9f37ca82d160', tool_call_id='call_Qyj7WfAgzWGCmbyM6EcPEnsf')]})\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='2925fabf-3c7e-4a14-9a72-531240436fbf'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 132, 'total_tokens': 222, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Ca9Mw5d8Cqw2CIFh7xs3xeT7LnCbe', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--390b0a79-531d-4131-8cba-c548963eab78-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco, CA'}, 'id': 'call_Qyj7WfAgzWGCmbyM6EcPEnsf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 90, 'total_tokens': 222, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}), ToolMessage(content=\"It's always sunny in San Francisco, CA!\", name='get_weather', id='da404a4e-7ca0-4c28-b19d-9f37ca82d160', tool_call_id='call_Qyj7WfAgzWGCmbyM6EcPEnsf'), AIMessage(content=\"It's always sunny in San Francisco, CA!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 172, 'total_tokens': 184, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Ca9Mz247AYCN8BqF1mFucttqj5PsW', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--f48a5389-1034-4b58-a89f-c8bfb39339fd-0', usage_metadata={'input_tokens': 172, 'output_tokens': 12, 'total_tokens': 184, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]})\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.config import get_stream_writer\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    writer = get_stream_writer()\n",
    "    # stream any arbitrary data\n",
    "    writer(f\"Looking up data for city: {city}\")\n",
    "    writer(f\"Acquired data for city: {city}\")\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5-mini\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"values\", \"custom\"],\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4d7ef47-e857-4e07-a233-888306e3e0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('custom', 'Looking up data for city: San Francisco, CA')\n",
      "('custom', 'Acquired data for city: San Francisco, CA')\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"custom\"],\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3845c067-761f-46a0-817c-2cc42066ce9a",
   "metadata": {},
   "source": [
    "## Try different modes on your own!\n",
    "Modify the stream mode and the select to produce different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92943e4f-6c17-4fa3-ad00-f86464ba66f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='79d6ff20-a97e-4e67-9bd5-40790821c14c')]}\n",
      "{'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='79d6ff20-a97e-4e67-9bd5-40790821c14c'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 154, 'prompt_tokens': 132, 'total_tokens': 286, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 128, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Ca9VOH3NSyLpf5DsiMxZXsAwxycpk', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--9bca45db-9da8-4c5d-a70d-cbd93a1122f8-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco, CA'}, 'id': 'call_UJMpQ0gUCnMwKDWKtQXPuX3a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 154, 'total_tokens': 286, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 128}})]}\n",
      "{'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='79d6ff20-a97e-4e67-9bd5-40790821c14c'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 154, 'prompt_tokens': 132, 'total_tokens': 286, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 128, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Ca9VOH3NSyLpf5DsiMxZXsAwxycpk', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--9bca45db-9da8-4c5d-a70d-cbd93a1122f8-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco, CA'}, 'id': 'call_UJMpQ0gUCnMwKDWKtQXPuX3a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 154, 'total_tokens': 286, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 128}}), ToolMessage(content=\"It's always sunny in San Francisco, CA!\", name='get_weather', id='58c6630c-95da-4395-9365-21503e7eb596', tool_call_id='call_UJMpQ0gUCnMwKDWKtQXPuX3a')]}\n",
      "{'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='79d6ff20-a97e-4e67-9bd5-40790821c14c'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 154, 'prompt_tokens': 132, 'total_tokens': 286, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 128, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Ca9VOH3NSyLpf5DsiMxZXsAwxycpk', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--9bca45db-9da8-4c5d-a70d-cbd93a1122f8-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco, CA'}, 'id': 'call_UJMpQ0gUCnMwKDWKtQXPuX3a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 154, 'total_tokens': 286, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 128}}), ToolMessage(content=\"It's always sunny in San Francisco, CA!\", name='get_weather', id='58c6630c-95da-4395-9365-21503e7eb596', tool_call_id='call_UJMpQ0gUCnMwKDWKtQXPuX3a'), AIMessage(content='I checked — \"It\\'s always sunny in San Francisco, CA!\" \\n\\nWould you like more details (current temperature, hourly forecast, wind, or forecast for a specific day)?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 172, 'prompt_tokens': 172, 'total_tokens': 344, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 128, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Ca9VRJ4ZH1MTw1Nm2m2ntqLMi1tGo', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--22742984-2152-48bc-8578-e075033f19c5-0', usage_metadata={'input_tokens': 172, 'output_tokens': 172, 'total_tokens': 344, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 128}})]}\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"values\"],\n",
    "):\n",
    "    if chunk[0] == \"values\":\n",
    "        print(chunk[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_essentials_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
